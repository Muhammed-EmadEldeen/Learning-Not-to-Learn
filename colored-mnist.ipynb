{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":474866,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":382077,"modelId":401638}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Notebook is my try to implement \"Learning Not To Learn\" paper\nWhile I succesfully captured the main points of the papers and done them correctly \nI wasn't able to reach their accuracy.","metadata":{}},{"cell_type":"markdown","source":"### Loading Modules","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport random\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:28.871882Z","iopub.execute_input":"2025-07-16T17:05:28.872385Z","iopub.status.idle":"2025-07-16T17:05:36.073834Z","shell.execute_reply.started":"2025-07-16T17:05:28.872360Z","shell.execute_reply":"2025-07-16T17:05:36.073251Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data = datasets.mnist.MNIST(\"./\",download = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:36.074809Z","iopub.execute_input":"2025-07-16T17:05:36.075166Z","iopub.status.idle":"2025-07-16T17:05:40.209204Z","shell.execute_reply.started":"2025-07-16T17:05:36.075135Z","shell.execute_reply":"2025-07-16T17:05:40.208486Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 17.6MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 8.09MB/s]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"np.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:41.855895Z","iopub.execute_input":"2025-07-16T17:05:41.856385Z","iopub.status.idle":"2025-07-16T17:05:41.921813Z","shell.execute_reply.started":"2025-07-16T17:05:41.856366Z","shell.execute_reply":"2025-07-16T17:05:41.921246Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Generation of random colors and assigning them to digits","metadata":{}},{"cell_type":"code","source":"random_colors = np.random.randint(255,size=(10,3))\ndigits_mean_color = np.arange(0,10)\nnp.random.shuffle(digits_mean_color)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:44.157659Z","iopub.execute_input":"2025-07-16T17:05:44.157954Z","iopub.status.idle":"2025-07-16T17:05:44.162269Z","shell.execute_reply.started":"2025-07-16T17:05:44.157931Z","shell.execute_reply":"2025-07-16T17:05:44.161471Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data.data.shape[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:48.362650Z","iopub.execute_input":"2025-07-16T17:05:48.363216Z","iopub.status.idle":"2025-07-16T17:05:48.368148Z","shell.execute_reply.started":"2025-07-16T17:05:48.363192Z","shell.execute_reply":"2025-07-16T17:05:48.367619Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"60000"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### Loading the dataset\n#### For each item we get the image, label, bias\n#### First we inject the color bias into data\n#### then return the biased image, label, bias","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, training_size, data, random_colors=random_colors, mean_colors = digits_mean_color):\n        self.data = data\n        self.size = training_size\n        self.random_colors = random_colors\n        self.mean_colors = mean_colors\n        \n    def __len__(self):\n        return self.size\n\n    def __getitem__(self, index):\n        gray_image = data.data[index].float()/255.0\n        label = data.targets[index]   \n        current_mean_color = self.mean_colors[label]\n        color= np.random.normal(self.random_colors[current_mean_color],20,size=(3))\n        color = np.clip(color,0,255)\n        colored_image = (gray_image.view(1,28,28)*(torch.from_numpy(color).float().view(3,1,1))/255.0)\n        return (colored_image,label,current_mean_color)\n\n\ntraining_size = int(0.9*data.data.shape[0])\ntrain_dataset = TrainDataset(training_size=training_size, data = data)\ntrain_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:49.408090Z","iopub.execute_input":"2025-07-16T17:05:49.408556Z","iopub.status.idle":"2025-07-16T17:05:49.415158Z","shell.execute_reply.started":"2025-07-16T17:05:49.408535Z","shell.execute_reply":"2025-07-16T17:05:49.414409Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### The same is done for testing dataset, However the color injected is choosen randomly","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, training_size, data, random_colors=random_colors, mean_colors = digits_mean_color):\n        self.data = data\n        self.size = training_size\n        self.random_colors = random_colors\n        self.mean_colors = mean_colors\n        \n    def __len__(self):\n        return data.data.shape[0] - self.size\n\n    def __getitem__(self, index):\n\n        index = index + self.size\n        \n        gray_image = self.data.data[index].float()/255.0\n        label = data.targets[index] \n        color_label = random.randint(0,9)\n        color= np.random.normal(self.random_colors[color_label],20,size=(3))\n        color = np.clip(color,0,255)\n        colored_image = (gray_image.view(1,28,28)*(torch.from_numpy(color).float().view(3,1,1))/255.0)\n        return (colored_image,label,color_label)\n\n\ntest_dataset = TestDataset(training_size=training_size, data = data)\ntest_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### In the paper the architecture specified is two conv layers for each part. \n* Two for f (Main stem).\n* Two for g (main head for classifying digits).\n* Two for h (for classifying bias label)","metadata":{}},{"cell_type":"code","source":"\nclass Convy(nn.Module):\n    def __init__(self, input_channels=3, dim=28, num_classes=10):\n        super(Convy, self).__init__()\n        \n        self.conv1f = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n        self.batchNorm1f = nn.BatchNorm2d(16)\n        self.conv2f = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n        self.batchNorm2f = nn.BatchNorm2d(32)\n        \n        \n        self.conv1g = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n        self.batchNorm1g = nn.BatchNorm2d(64)\n        self.conv2g = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n        self.batchNorm2g = nn.BatchNorm2d(64)\n        self.fc_g = nn.Linear(64, num_classes)  \n\n        \n        self.conv1h = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size = 3)\n        self.batchNorm1h = nn.BatchNorm2d(64)\n        self.conv2h = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size = 3)\n        self.batchNorm2h = nn.BatchNorm2d(64)\n        self.fc_h = nn.Linear(64, num_classes)\n\n        self.pool = nn.MaxPool2d(2, 2)\n        self.relu = nn.ReLU()\n\n        self.soft = torch.nn.Softmax(dim = 1)\n        \n\n    def f_parameters(self):\n        return list(self.conv1f.parameters()) + list(self.conv2f.parameters())\n\n    def g_parameters(self):\n        return list(self.conv1g.parameters()) + list(self.conv2g.parameters()) + list(self.fc_g.parameters())\n\n    def h_parameters(self):\n        return list(self.conv1h.parameters()) + list(self.conv2h.parameters()) + list(self.fc_h.parameters())\n\n        \n    def forward(self, img):\n        f = self.pool(self.relu(self.batchNorm1f(self.conv1f(img))))\n        f = self.pool(self.relu(self.batchNorm2f(self.conv2f(f))))\n\n        g = self.relu(self.conv1g(f))\n        g = self.pool(self.relu(self.conv2g(g)))\n        g = g.view(g.size(0), -1)\n        g = self.fc_g(g)\n\n        h = self.relu(self.conv1h(f))\n        h = self.pool(self.relu(self.conv2h(h)))\n        h = h.view(h.size(0), -1)\n        h = self.fc_h(h)\n        \n\n        return g,h\n        \n\n    def predict_number(self,img):\n        f = self.pool(self.relu(self.batchNorm1f(self.conv1f(img))))\n        f = self.pool(self.relu(self.batchNorm2f(self.conv2f(f))))\n\n        g = self.relu(self.batchNorm1g(self.conv1g(f)))\n        g = self.pool(self.relu(self.batchNorm2g(self.conv2g(g))))\n        g = g.view(g.size(0), -1)\n        g = self.fc_g(g)\n\n\n        return g\n\n    def predict_bias_inv(self,img):\n        f = self.pool(self.relu(self.batchNorm1f(self.conv1f(img))))\n        f = self.pool(self.relu(self.batchNorm2f(self.conv2f(f))))\n        \n        f = GradientReversal.apply(f)\n\n        h = self.relu(self.batchNorm1h(self.conv1h(f)))\n        h = self.pool(self.relu(self.batchNorm2h(self.conv2h(h))))\n        h = h.view(h.size(0), -1)\n        h = self.fc_h(h)\n\n        return h\n\n    def predict_bias(self,img):\n        f = self.pool(self.relu(self.batchNorm1f(self.conv1f(img))))\n        f = self.pool(self.relu(self.batchNorm2f(self.conv2f(f))))\n\n        h = self.relu(self.batchNorm1h(self.conv1h(f)))\n        h = self.pool(self.relu(self.batchNorm2h(self.conv2h(h))))\n        h = h.view(h.size(0), -1)\n        h = self.fc_h(h)\n\n        return h\n\n\n        \n        \n        \nclass GradientReversal(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x):\n        return x.view_as(x)\n    \n    @staticmethod\n    def backward(ctx, grad_output):\n        return -grad_output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:54.654288Z","iopub.execute_input":"2025-07-16T17:05:54.654906Z","iopub.status.idle":"2025-07-16T17:05:54.668522Z","shell.execute_reply.started":"2025-07-16T17:05:54.654881Z","shell.execute_reply":"2025-07-16T17:05:54.667880Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = Convy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:09:48.582420Z","iopub.execute_input":"2025-07-16T17:09:48.582761Z","iopub.status.idle":"2025-07-16T17:09:48.590912Z","shell.execute_reply.started":"2025-07-16T17:09:48.582722Z","shell.execute_reply":"2025-07-16T17:09:48.590275Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"max_acc = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:05:59.719009Z","iopub.execute_input":"2025-07-16T17:05:59.719485Z","iopub.status.idle":"2025-07-16T17:05:59.722570Z","shell.execute_reply.started":"2025-07-16T17:05:59.719467Z","shell.execute_reply":"2025-07-16T17:05:59.721958Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"optimizer_f = optim.Adam(model.f_parameters(), lr=1e-3,weight_decay=1e-3)\noptimizer_g = optim.Adam(model.g_parameters(), lr=1e-3,weight_decay=1e-3)\noptimizer_h = optim.Adam(model.h_parameters(), lr=1e-3,weight_decay=1e-3)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:09:51.312187Z","iopub.execute_input":"2025-07-16T17:09:51.312450Z","iopub.status.idle":"2025-07-16T17:09:51.318003Z","shell.execute_reply.started":"2025-07-16T17:09:51.312431Z","shell.execute_reply":"2025-07-16T17:09:51.317299Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"device = torch.device(\"cuda\")\nseed = 42\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:06:06.838062Z","iopub.execute_input":"2025-07-16T17:06:06.838326Z","iopub.status.idle":"2025-07-16T17:06:06.843948Z","shell.execute_reply.started":"2025-07-16T17:06:06.838307Z","shell.execute_reply":"2025-07-16T17:06:06.843238Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/working/mnist_best.pt\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T13:07:00.696072Z","iopub.execute_input":"2025-07-16T13:07:00.696396Z","iopub.status.idle":"2025-07-16T13:07:00.713191Z","shell.execute_reply.started":"2025-07-16T13:07:00.696365Z","shell.execute_reply":"2025-07-16T13:07:00.712686Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-16T12:02:20.413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, dataloader, device='cuda'):\n    model.eval()\n    correct = total = 0\n    correct_bias = total_bias = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x_batch, y_batch, y_bias in dataloader:\n            x_batch = x_batch.to(device, torch.float32)\n            y_batch = y_batch.to(device)\n            y_bias = y_bias.to(device)\n            \n            logits = model.predict_number(x_batch)  \n            probs = torch.softmax(logits, dim=1)  \n            preds = torch.argmax(probs, dim=1)  \n\n            logits_bias = model.predict_bias(x_batch)\n            probs_bias = torch.softmax(logits_bias, dim=1)  \n            preds_bias= torch.argmax(probs_bias, dim=1)\n\n            correct += (preds == y_batch).sum().item()\n            total += y_batch.size(0)\n\n            correct_bias += (preds_bias == y_bias).sum().item()\n            total_bias += y_bias.size(0)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y_batch.cpu().numpy())\n\n\n    accuracy = 100.0 * correct / total \n    f1 = f1_score(all_labels, all_preds, average='weighted')\n\n    accuracy2 = 100.0* correct_bias/total_bias\n\n    return accuracy, f1, accuracy2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T17:06:09.827985Z","iopub.execute_input":"2025-07-16T17:06:09.828488Z","iopub.status.idle":"2025-07-16T17:06:09.834389Z","shell.execute_reply.started":"2025-07-16T17:06:09.828468Z","shell.execute_reply":"2025-07-16T17:06:09.833833Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\ndef train(train_dataloader,lambda_,mu):\n    number_of_samples = 0\n    batch_loss = 0\n    batch_loss_pred=0\n    model.to(device)\n    model.train()\n\n    for batch_idx, (input, target_label, bias_label) in enumerate(train_dataloader):\n        input, target_label, bias_label = input.to(device), target_label.to(device), bias_label.to(device)\n\n        optimizer_h.zero_grad()\n        bias_preds = model.predict_bias(input)\n        loss_bias_h = criterion(bias_preds, bias_label)\n        loss_bias_h.backward()\n        optimizer_h.step()\n\n        \n        optimizer_f.zero_grad()\n        bias_probs = F.softmax(model.predict_bias(input), dim=1)\n        entropy = torch.sum(bias_probs * torch.log(bias_probs + 1e-8), dim=1).mean()\n        loss_entropy = lambda_ * entropy\n        bias_preds_inv = model.predict_bias_inv(input)\n        loss_bias_f = criterion(bias_preds_inv, bias_label) * mu\n        loss_f = loss_entropy + loss_bias_f\n        loss_f.backward()\n        optimizer_f.step()\n\n        # Step 3: Train f and g to minimize classification loss\n        optimizer_f.zero_grad()\n        optimizer_g.zero_grad()\n        outputs = model.predict_number(input)\n        loss_main = criterion(outputs, target_label)\n        loss_main.backward()\n        optimizer_f.step()\n        optimizer_g.step()\n\n        number_of_samples += 1\n        batch_loss += loss_main.item() + loss_bias_f.item() + loss_entropy.item()\n        batch_loss_pred += loss_main.item()\n        print(evaluate(model, test_dataloader))\n\n    return batch_loss, batch_loss_pred\n\n\nfor _ in range(1):\n    train_batches_error = []\n    print(train(train_dataloader,0.01,0.1))\n    test_acc, train_f1,test_bias = evaluate(model, test_dataloader)\n    print(evaluate(model,train_dataloader))\n    print(test_acc)\n    if test_acc > max_acc:\n        max_acc = test_acc\n        torch.save(model.state_dict(), \"best_model_mi.pt\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### As stated I haven't been able to reach their Accuracy.\n### It's apparent that this model is better than the regular model for dealing with bias\n### However it's still far from good","metadata":{}},{"cell_type":"code","source":"evaluate(model,test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T13:48:17.736837Z","iopub.execute_input":"2025-07-16T13:48:17.737123Z","iopub.status.idle":"2025-07-16T13:48:18.219394Z","shell.execute_reply.started":"2025-07-16T13:48:17.737094Z","shell.execute_reply":"2025-07-16T13:48:18.218654Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"(42.21666666666667, 0.42573449498261473, 52.61666666666667)"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/mnist_best.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T12:30:56.959064Z","iopub.execute_input":"2025-07-16T12:30:56.959783Z","iopub.status.idle":"2025-07-16T12:30:56.970337Z","shell.execute_reply.started":"2025-07-16T12:30:56.959755Z","shell.execute_reply":"2025-07-16T12:30:56.969709Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"colored_digit = (data.data[51000].view(1,28,28)*torch.from_numpy(color).view(3,1,1))//(255)\ncolored_digit = colored_digit.to(torch.uint8)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-16T12:02:20.413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"color = (random_colors[digits_mean_color[7]] + np.random.normal(0,20,size=(3)))\ncolor = np.clip(color,0,255)\ngray = data.data[40578].float()/255.0\ncolored_digit = (gray.view(1,28,28)*(torch.from_numpy(color).float().view(3,1,1))/255.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T13:08:02.463169Z","iopub.execute_input":"2025-07-16T13:08:02.464001Z","iopub.status.idle":"2025-07-16T13:08:02.468740Z","shell.execute_reply.started":"2025-07-16T13:08:02.463974Z","shell.execute_reply":"2025-07-16T13:08:02.468156Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"colored_digit_d=colored_digit.view(1,3,28,28).to(device)\nnp.argmax(model.predict_number(colored_digit_d).cpu().detach().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T13:08:02.852961Z","iopub.execute_input":"2025-07-16T13:08:02.853676Z","iopub.status.idle":"2025-07-16T13:08:02.860614Z","shell.execute_reply.started":"2025-07-16T13:08:02.853651Z","shell.execute_reply":"2025-07-16T13:08:02.859899Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"plt.imshow(colored_digit.permute(1, 2, 0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T13:08:03.751164Z","iopub.execute_input":"2025-07-16T13:08:03.751785Z","iopub.status.idle":"2025-07-16T13:08:03.896595Z","shell.execute_reply.started":"2025-07-16T13:08:03.751757Z","shell.execute_reply":"2025-07-16T13:08:03.895866Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7a62c81a3910>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}